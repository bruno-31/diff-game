{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "% pylab inline\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from tensorflow.contrib.kfac.python.ops.utils import fwd_gradients\n",
    "import seaborn as sns\n",
    "try:\n",
    "    from moviepy.video.io.bindings import mplfig_to_npimage\n",
    "    import moviepy.editor as mpy\n",
    "except:\n",
    "    print(\"Warning: moviepy not found.\")\n",
    "\n",
    "slim = tf.contrib.slim\n",
    "ds = tf.contrib.distributions\n",
    "\n",
    "from universal_divergence import estimate\n",
    "from utils import nn_l2_mean\n",
    "\n",
    "from functools import reduce\n",
    "from operator import mul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from optimizers import OptimisticAdamOptimizer, OptimisticMirrorDescentOptimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Generator and discriminator architectures\n",
    "\n",
    "(same architecture as proposed in google brain paper)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator(z, output_dim=2, n_hidden=512, n_layer=4, getter=None, reuse=False):\n",
    "    with tf.variable_scope(\"generator\", custom_getter=getter, reuse=reuse):\n",
    "        h = slim.stack(z, slim.fully_connected, [n_hidden] * n_layer, activation_fn=tf.nn.relu)\n",
    "        x = slim.fully_connected(h, output_dim, activation_fn=None)\n",
    "    return x\n",
    "\n",
    "def discriminator(x, n_hidden=512, n_layer=4, getter=None, reuse=False):\n",
    "    with tf.variable_scope(\"discriminator\", custom_getter=getter, reuse=reuse):\n",
    "        h = slim.stack(x, slim.fully_connected, [n_hidden] * n_layer, activation_fn=tf.nn.relu)\n",
    "        log_d = slim.fully_connected(h, 1, activation_fn=None)\n",
    "    return log_d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_mog(batch_size, n_mixture=16, std=0.2):\n",
    "    x = np.linspace(-4.5,4.5,4)\n",
    "    xs, ys = np.meshgrid(x, x)\n",
    "    xs, ys = xs.flatten(), ys.flatten()\n",
    "    cat = ds.Categorical(tf.zeros(n_mixture))\n",
    "    comps = [ds.MultivariateNormalDiag([xi, yi], [std, std]) for xi, yi in zip(xs.ravel(), ys.ravel())]\n",
    "    data = ds.Mixture(cat, comps)\n",
    "    return data.sample(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_mnist_and_sample(batch_size):\n",
    "    from tensorflow.examples.tutorials.mnist import input_data\n",
    "    mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "    from sampler import sampler\n",
    "    \n",
    "    im=mnist.train.next_batch(1)[0]\n",
    "    im=im.reshape([28,28])\n",
    "    \n",
    "    x = np.linspace(0, 1, 28)\n",
    "    y = np.linspace(0, 1,28)\n",
    "    xv, yv = np.meshgrid(x, y)\n",
    "    z=im\n",
    "    s=sampler(x,y,z)\n",
    "    vals = s.sample(batch_size)\n",
    "    \n",
    "    return vals,im\n",
    "    \n",
    "def plot_vals_im(vals,im):\n",
    "    xVals = []; yVals = []\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=2)\n",
    "    for item in vals:  # plot point by point\n",
    "            xVals.append(item[0])\n",
    "            yVals.append(item[1])\n",
    "            ax[0].plot(item[0], 1-item[1], marker=\"x\", c=\"red\")\n",
    "            ax[0].set_title('Complex distribution')\n",
    "    \n",
    "    ax[1].imshow(im,cmap='gray')\n",
    "    ax[1].set_title('Original Image')\n",
    "    plt.show()\n",
    "\n",
    "def sample_complex(batch_size):\n",
    "    vals, im = load_mnist_and_sample(batch_size)\n",
    "    plot_vals_im(vals,im)\n",
    "    \n",
    "    return tf.stack(vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = dict(\n",
    "    batch_size=512,\n",
    "    disc_learning_rate=5e-5,\n",
    "    gen_learning_rate=5e-5,\n",
    "    beta1=0.5,\n",
    "    epsilon=1e-8,\n",
    "    max_iter=20000,\n",
    "    frame_every=2000, \n",
    "    viz_every=2000,\n",
    "    z_dim=2,\n",
    "    x_dim=2,\n",
    "    optimizer='default', # prop sgd sga\n",
    "    ema = False,\n",
    "    align = True,\n",
    "    data = 'mog',\n",
    "    LAMBDA = .1,\n",
    "    mode = 'wgan-gp',\n",
    "    generate_movie = False,\n",
    "    reg_w = 10,\n",
    "    CRITIC_ITERS = 5 # How many critic iterations per generator iteration\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for Symplectic gradient adjustment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def jac_vec(ys,xs,vs):\n",
    "    return fwd_gradients(ys,xs,grad_xs=vs, stop_gradients=xs)\n",
    "\n",
    "def jac_tran_vec(ys,xs,vs):\n",
    "    dydxs = tf.gradients(ys,xs,grad_ys=vs, stop_gradients=xs)\n",
    "    return [tf.zeros_like(x) if dydx is None else dydx for (x,dydx) in zip(xs,dydxs)]\n",
    "\n",
    "def get_sym_adj(Ls,xs):\n",
    "    xi= [tf.gradients(l,x)[0]for(l,x)in zip(Ls,xs)]\n",
    "    H_xi = jac_vec(xi,xs,xi)\n",
    "    Ht_xi = jac_tran_vec(xi,xs,xi)\n",
    "    At_xi =[(ht-h)/2 for (h,ht) in zip(H_xi,Ht_xi)]\n",
    "    return At_xi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct model and training ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "data = sample_complex(params['batch_size']) if params['data']=='complex' else sample_mog(params['batch_size'])\n",
    "noise = ds.Normal(tf.zeros(params['z_dim']), tf.ones(params['z_dim'])).sample(params['batch_size'])\n",
    "\n",
    "# Construct generator and discriminator nets\n",
    "with slim.arg_scope([slim.fully_connected], weights_initializer=tf.orthogonal_initializer(gain=1.4)):\n",
    "    samples = generator(noise, output_dim=params['x_dim'])\n",
    "    real_score = discriminator(data)\n",
    "    fake_score = discriminator(samples, reuse=True)\n",
    "    \n",
    "# Saddle objective    \n",
    "loss = tf.reduce_mean(\n",
    "    tf.nn.sigmoid_cross_entropy_with_logits(logits=real_score, labels=tf.ones_like(real_score)) +\n",
    "    tf.nn.sigmoid_cross_entropy_with_logits(logits=fake_score, labels=tf.zeros_like(fake_score)))\n",
    "\n",
    "loss_gen = -tf.reduce_mean(fake_score)\n",
    "loss_dis = tf.reduce_mean(fake_score) - tf.reduce_mean(real_score)\n",
    "\n",
    "gen_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"generator\")\n",
    "disc_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"discriminator\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WGAN or WGAN-GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if params['mode'] == 'wgan':\n",
    "    \n",
    "    clip_ops = []\n",
    "    for var in disc_vars:\n",
    "        clip_bounds = [-.01, .01]\n",
    "        clip_ops.append(\n",
    "            tf.assign(\n",
    "                var, \n",
    "                tf.clip_by_value(var, clip_bounds[0], clip_bounds[1])\n",
    "            )\n",
    "        )\n",
    "    clip_disc_weights = tf.group(*clip_ops)\n",
    "    \n",
    "elif params['mode'] == 'wgan-gp':\n",
    "    fake_data = samples\n",
    "    real_data = data\n",
    "\n",
    "    # Gradient penalty\n",
    "    alpha = tf.random_uniform(\n",
    "        shape=[params['batch_size'],1], \n",
    "        minval=0.,\n",
    "        maxval=1.\n",
    "    )\n",
    "    differences = fake_data - real_data\n",
    "    interpolates = real_data + (alpha*differences)\n",
    "    gradients = tf.gradients(discriminator(interpolates,reuse=True), [interpolates])[0]\n",
    "    slopes = tf.sqrt(tf.reduce_sum(tf.square(gradients), reduction_indices=[1]))\n",
    "    gradient_penalty = tf.reduce_mean((slopes-1.)**2)\n",
    "    loss_dis += params['LAMBDA']*gradient_penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if params['optimizer'] == 'default':\n",
    "    \n",
    "    if params['mode']=='wgan':\n",
    "        d_train_opt = tf.train.RMSPropOptimizer(learning_rate=5e-5)\n",
    "        g_train_opt = tf.train.RMSPropOptimizer(learning_rate=5e-5)\n",
    "    \n",
    "    elif params['mode']=='wgan-gp':\n",
    "        d_train_opt = tf.train.AdamOptimizer(learning_rate=1e-4, beta1=0.5, beta2=0.9)\n",
    "        g_train_opt = tf.train.AdamOptimizer(learning_rate=1e-4, beta1=0.5, beta2=0.9)\n",
    "\n",
    "    d_train_op = d_train_opt.minimize(loss_dis, var_list=disc_vars)\n",
    "    g_train_op = g_train_opt.minimize(loss_gen, var_list=gen_vars)\n",
    "\n",
    "elif params['optimizer'] == 'default_ema':\n",
    "    \n",
    "    if params['mode']=='wgan':\n",
    "        d_train_opt = tf.train.RMSPropOptimizer(learning_rate=5e-5)\n",
    "        g_train_opt = tf.train.RMSPropOptimizer(learning_rate=5e-5)\n",
    "    \n",
    "    elif params['mode']=='wgan-gp':\n",
    "        d_train_opt = tf.train.AdamOptimizer(learning_rate=1e-4, beta1=0.5, beta2=0.9)\n",
    "        g_train_opt = tf.train.AdamOptimizer(learning_rate=1e-4, beta1=0.5, beta2=0.9)\n",
    "\n",
    "    d_train_op = d_train_opt.minimize(loss_dis, var_list=disc_vars)\n",
    "    g_train_op = g_train_opt.minimize(loss_gen, var_list=gen_vars)\n",
    "\n",
    "    ema = tf.train.ExponentialMovingAverage(decay=0.999)\n",
    "    maintain_averages_op = ema.apply(gen_vars)\n",
    "    with tf.control_dependencies([g_train_op]):\n",
    "        g_train_op = tf.group(maintain_averages_op)\n",
    "    samples_ema = generator(noise, output_dim=params['x_dim'], getter=get_getter(ema),reuse=True)\n",
    "\n",
    "elif params['optimizer'] == 'omd':\n",
    "    d_train_opt = OptimisticMirrorDescentOptimizer(learning_rate=5e-5)\n",
    "    g_train_opt = OptimisticMirrorDescentOptimizer(learning_rate=5e-5)\n",
    "    \n",
    "    d_train_op = d_train_opt.minimize(loss_dis, var_list=disc_vars)\n",
    "    g_train_op = g_train_opt.minimize(loss_gen, var_list=gen_vars)\n",
    "    \n",
    "elif params['optimizer'] == 'optimadam':\n",
    "    d_train_opt = OptimisticAdamOptimizer(learning_rate=1e-4, beta1=0.5, beta2=0.9)\n",
    "    g_train_opt = OptimisticAdamOptimizer(learning_rate=1e-4, beta1=0.5, beta2=0.9)\n",
    "    \n",
    "    d_train_op = d_train_opt.minimize(loss_dis, var_list=disc_vars)\n",
    "    g_train_op = g_train_opt.minimize(loss_gen, var_list=gen_vars)\n",
    "\n",
    "elif params['optimizer'] == 'sga': \n",
    "\n",
    "    d_opt = tf.train.RMSPropOptimizer(learning_rate=params['disc_learning_rate'])\n",
    "    g_opt = tf.train.RMSPropOptimizer(learning_rate=params['gen_learning_rate'])\n",
    "\n",
    "    dvs = d_opt.compute_gradients(loss_dis, var_list=disc_vars)\n",
    "    gvs = g_opt.compute_gradients(loss_gen, var_list=gen_vars)\n",
    "\n",
    "    adj = get_sym_adj([loss_dis]*len(disc_vars) + [loss_gen]*len(gen_vars),disc_vars+gen_vars)\n",
    "    d_adj= adj[:len(disc_vars)]\n",
    "    g_adj = adj[-len(gen_vars)::]\n",
    "\n",
    "    dvs_sga = [(grad + adj , var) for (grad,var),adj in zip(dvs,d_adj)]\n",
    "    gvs_sga = [(grad + adj , var) for (grad,var),adj in zip(gvs,g_adj)]\n",
    "\n",
    "    d_train_op = d_opt.apply_gradients(dvs_sga)\n",
    "    g_train_op = g_opt.apply_gradients(gvs_sga)\n",
    "    \n",
    "elif params['optimizer'] == 'consensus': \n",
    "    \n",
    "    d_opt = tf.train.RMSPropOptimizer(learning_rate=params['disc_learning_rate'], use_locking=True)\n",
    "    g_opt = tf.train.RMSPropOptimizer(learning_rate=params['gen_learning_rate'], use_locking=True)\n",
    "\n",
    "    dvs = d_opt.compute_gradients(loss, var_list=disc_vars)\n",
    "    gvs = g_opt.compute_gradients(-loss, var_list=gen_vars)\n",
    "\n",
    "    grads_d = [grad for (grad,var) in dvs]\n",
    "    grads_g = [grad for (grad,var) in gvs]\n",
    "    grads = grads_d + grads_g\n",
    "\n",
    "    # Regularizer\n",
    "    reg = 0.5 * sum(tf.reduce_sum(tf.square(g)) for g in grads)\n",
    "    # Jacobian times gradiant\n",
    "    variables = disc_vars + gen_vars\n",
    "    Jgrads = tf.gradients(reg, variables)\n",
    "    \n",
    "    d_adj = Jgrads[:len(disc_vars)]\n",
    "    g_adj = Jgrads[-len(gen_vars)::]\n",
    "    \n",
    "\n",
    "    dvs_sga = [(grad + params['reg_w'] * adj , var) for (grad,var),adj in zip(dvs,d_adj)]\n",
    "    gvs_sga = [(grad + params['reg_w'] * adj , var) for (grad,var),adj in zip(gvs,g_adj)]\n",
    "    \n",
    "    with tf.control_dependencies([g for (g, v) in dvs_sga]):\n",
    "        d_train_op = d_opt.apply_gradients(dvs_sga)\n",
    "    with tf.control_dependencies([g for (g, v) in dvs_sga]):\n",
    "        g_train_op = g_opt.apply_gradients(gvs_sga)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/20001 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8281105a58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 199/20001 [00:15<14:31, 22.71it/s]  "
     ]
    }
   ],
   "source": [
    "xmax = 3\n",
    "fs = []\n",
    "raw_frames = []\n",
    "np_samples = []\n",
    "n_batches_viz = 10\n",
    "viz_every = params['viz_every']\n",
    "frame_every = params['frame_every']\n",
    "\n",
    "nn_every = 200\n",
    "y_ref = sess.run(data)\n",
    "nn_dist = []\n",
    "nn_kl =[]\n",
    "\n",
    "for i in tqdm(range(params['max_iter']+1)):\n",
    "    f, _ = sess.run([[loss], g_train_op])\n",
    "    for j in range(params['CRITIC_ITERS']):\n",
    "        _ = sess.run(d_train_op)\n",
    "        if params['mode'] == 'wgan':\n",
    "            _ = sess.run(clip_disc_weights)\n",
    "    fs.append(f)\n",
    "    if (i) % frame_every == 0:\n",
    "        if params['optimizer'] == 'default_ema':\n",
    "            np_samples.append(np.vstack([sess.run(samples_ema) for _ in range(n_batches_viz)]))\n",
    "            xx, yy = sess.run([samples_ema, data])\n",
    "        else:\n",
    "            np_samples.append(np.vstack([sess.run(samples) for _ in range(n_batches_viz)]))\n",
    "            xx, yy = sess.run([samples, data])\n",
    "\n",
    "        fig = figure(figsize=(5,5))\n",
    "        scatter(xx[:, 0], xx[:, 1], edgecolor='none',s=10)\n",
    "        scatter(yy[:, 0], yy[:, 1], c='g', edgecolor='none',s=10)\n",
    "        if params[\"data\"]==\"complex\":\n",
    "            plt.xlim([-0.2, 1.2])\n",
    "            plt.ylim([-0.2, 1.2])\n",
    "        else:\n",
    "            plt.xlim([-5.5, 5.5])\n",
    "            plt.ylim([-5.5, 5.5])\n",
    "        axis('off')\n",
    "        if params['generate_movie']:\n",
    "            raw_frames.append(mplfig_to_npimage(fig))\n",
    "        if (i) % viz_every == 0:\n",
    "            show()\n",
    "            \n",
    "    if (i) % nn_every == 0:\n",
    "        if params['optimizer'] == 'default_ema':\n",
    "            x = np.vstack([sess.run(samples_ema) for _ in range(n_batches_viz)])\n",
    "        else:\n",
    "            x = np.vstack([sess.run(samples) for _ in range(n_batches_viz)])\n",
    "        l2nn = nn_l2_mean(x,y_ref)\n",
    "        kl =estimate(x, y_ref,k=1)\n",
    "        nn_dist.append(l2nn)\n",
    "        nn_kl.append(kl)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np_samples_ = np_samples[::1]\n",
    "vizu_frames = []\n",
    "cols = len(np_samples_)\n",
    "figure(figsize=(2*cols, 2))\n",
    "for i, samps in enumerate(np_samples_):\n",
    "    if i == 0:\n",
    "        ax = subplot(1,cols,1)\n",
    "    else:\n",
    "        subplot(1,cols,i+1, sharex=ax, sharey=ax)\n",
    "    ax2 = sns.kdeplot(samps[:, 0], samps[:, 1], shade=True, cmap='coolwarm', bw=.40, n_levels=20, clip=[[-6,6]]*2)\n",
    "    xticks([]); yticks([])\n",
    "    title('step %d'%(i*viz_every))\n",
    "gcf().tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.semilogy(nn_dist)\n",
    "plt.semilogy(nn_kl)\n",
    "plt.legend(['kl','l2 nearest neigbhors'])\n",
    "xlabel('iterations')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('plot_{}_{}_kl'.format(params['mode'],params['optimizer']),nn_kl)\n",
    "np.save('plot_{}_{}_nn'.format(params['mode'],params['optimizer']),nn_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Video maker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if params['generate_movie']:\n",
    "    np_samples_ = np_samples[::1]\n",
    "    vizu_frames = []\n",
    "    cols = len(np_samples_)\n",
    "    bg_color  = sns.color_palette('Greens', n_colors=256)[0]\n",
    "    fig, ax = plt.subplots()\n",
    "    for i, samps in enumerate(np_samples_):\n",
    "        ax.clear()\n",
    "        ax2 = sns.kdeplot(samps[:, 0], samps[:, 1], shade=True, cmap='coolwarm', bw=.40, n_levels=20, clip=[[-6,6]]*2)\n",
    "\n",
    "        xticks([]); yticks([])\n",
    "        title('step %d'%(i*frame_every))\n",
    "        if generate_movie:\n",
    "            vizu_frames.append(mplfig_to_npimage(fig))\n",
    "    \n",
    "    # Generate movie\n",
    "    \n",
    "    raw_clip = mpy.ImageSequenceClip(raw_frames[::], fps=10)\n",
    "    raw_clip.write_videofile(\"raw_optimizer_{}_{}_{}.webm\".format(params['optimizer'], params['mode'], params['data']), audio=False)\n",
    "    vizu_clip = mpy.ImageSequenceClip(vizu_frames[::], fps=10)\n",
    "    vizu_clip.write_videofile(\"vizu_optimizer_{}_{}_{}.webm\".format(params['optimizer'], params['mode'], params['data']), audio=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF 1.6",
   "language": "python",
   "name": "tensorflow-1.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
