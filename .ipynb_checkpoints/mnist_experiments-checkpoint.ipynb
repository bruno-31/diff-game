{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-27T10:34:07.038427Z",
     "start_time": "2018-04-27T10:34:05.090997Z"
    },
    "nbpresent": {
     "id": "e97a0b34-c6d5-43e9-9d1f-47a4a3686d86"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from utils import *\n",
    "slim = tf.contrib.slim\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import os \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "from k_gan import generator,discriminator\n",
    "import utils\n",
    "l = tf.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "fa9716ff-c87d-497d-a2a9-2237d5545965"
    }
   },
   "source": [
    "## Hyperparam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-27T10:34:07.044259Z",
     "start_time": "2018-04-27T10:34:07.040456Z"
    },
    "nbpresent": {
     "id": "b110c295-2ec0-4c8e-8e48-3bbd0f1ca1f5"
    }
   },
   "outputs": [],
   "source": [
    "params = dict(\n",
    "    batch_size = 100,\n",
    "    seed = 1234,\n",
    "    z_dim = 2,\n",
    "    x_dim = 784,\n",
    "    reg_w = 0.,\n",
    "    lr = 2e-4,\n",
    "    logdir = 'gan_mnist/',\n",
    "    name_model = 'model_latent24'\n",
    ")\n",
    "rng = np.random.RandomState(params['seed'])  # seed labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "19d9e7b7-51bc-446b-a4cd-8f0691a2256b"
    }
   },
   "source": [
    "## Data creation (unl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-27T10:34:10.695678Z",
     "start_time": "2018-04-27T10:34:07.047430Z"
    },
    "nbpresent": {
     "id": "cfbc3cf4-97bb-4879-bd78-017af441a03e"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=False)\n",
    "trainx = np.vstack([mnist.train.images,mnist.validation.images])\n",
    "trainy = np.hstack([mnist.train.labels,mnist.validation.labels])\n",
    "testx = mnist.test.images\n",
    "testy = mnist.test.labels\n",
    "trainx = np.reshape(trainx,[-1,28,28,1])\n",
    "testx = np.reshape(testx,[-1,28,28,1])\n",
    "trainx_unl = trainx.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "b4a8b72b-abd1-4846-9c18-a1c7a5be8c7a"
    }
   },
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-27T10:34:13.506217Z",
     "start_time": "2018-04-27T10:34:13.503182Z"
    },
    "nbpresent": {
     "id": "37544c17-787c-4988-8cdd-d74d72c00c66"
    }
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-27T10:34:16.398308Z",
     "start_time": "2018-04-27T10:34:13.508278Z"
    },
    "nbpresent": {
     "id": "6b7a5e16-bd67-4962-97d0-89ccffb8ec42"
    }
   },
   "outputs": [],
   "source": [
    "unl_dataset = tf.data.Dataset.from_tensor_slices(trainx_unl)\n",
    "unl_dataset = unl_dataset.shuffle(10000).repeat().batch(params['batch_size'])\n",
    "\n",
    "iterator_unl = unl_dataset.make_one_shot_iterator()\n",
    "next_unl = iterator_unl.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-27T10:34:18.028953Z",
     "start_time": "2018-04-27T10:34:16.752139Z"
    },
    "nbpresent": {
     "id": "ba1a11eb-9791-4e9d-956f-7a8dcd36aef1"
    }
   },
   "outputs": [],
   "source": [
    "is_training_pl = tf.placeholder(tf.bool, [], name='is_training_pl')\n",
    "data = tf.cast(next_unl,tf.float32)\n",
    "noise = tf.random_normal(shape=[params['batch_size'],params['z_dim']])\n",
    "# Construct generator and discriminator net\n",
    "# samples = generator(noise,is_training_pl,reuse=False)\n",
    "# real_score = discriminator(data,is_training_pl,reuse=False)\n",
    "# fake_score = discriminator(samples,is_training_pl,reuse=True)\n",
    "\n",
    "samples = generator(noise,is_training=is_training_pl,reuse=tf.AUTO_REUSE)\n",
    "real_score = discriminator(data,is_training=is_training_pl,reuse=tf.AUTO_REUSE)\n",
    "fake_score = discriminator(samples,is_training=is_training_pl,reuse=tf.AUTO_REUSE)\n",
    "\n",
    "gen_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"generator\")\n",
    "disc_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"discriminator\") \n",
    "\n",
    "loss_g = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=fake_score,labels=tf.ones_like(fake_score)))\n",
    "loss_d = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=real_score,labels=tf.ones_like(fake_score)))+\\\n",
    "tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=fake_score,labels=tf.zeros_like(fake_score)))\n",
    "\n",
    "optimizer_dis = tf.train.AdamOptimizer(learning_rate=params['lr'],\n",
    "                                               beta1=0.5, name='dis_optimizer')\n",
    "optimizer_gen = tf.train.AdamOptimizer(learning_rate=params['lr'],\n",
    "                                               beta1=0.5, name='gen_optimizer')\n",
    "\n",
    "update_ops_gen = tf.get_collection(tf.GraphKeys.UPDATE_OPS,\n",
    "                                   scope='generator')\n",
    "update_ops_dis = tf.get_collection(tf.GraphKeys.UPDATE_OPS,\n",
    "                                   scope='discriminator')\n",
    "\n",
    "with tf.control_dependencies(update_ops_gen): # attached op for moving average batch norm\n",
    "    traing = optimizer_gen.minimize(loss_g,var_list=gen_vars)\n",
    "with tf.control_dependencies(update_ops_dis):\n",
    "    traind = optimizer_dis.minimize(loss_d,var_list=disc_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-27T10:34:24.948025Z",
     "start_time": "2018-04-27T10:34:18.031156Z"
    },
    "nbpresent": {
     "id": "5f362fc8-f4c7-4afe-9ed7-1287042286e8"
    }
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./saved_models/gan_mnist/model1\n"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "Key generator/fc1/batch_normalization/gamma not found in checkpoint\n\t [[Node: save/RestoreV2_47 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2_47/tensor_names, save/RestoreV2_47/shape_and_slices)]]\n\t [[Node: save/RestoreV2_45/_95 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_282_save/RestoreV2_45\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n\nCaused by op 'save/RestoreV2_47', defined at:\n  File \"/home/bruno/anaconda3/envs/tensorflow/lib/python3.5/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/bruno/anaconda3/envs/tensorflow/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/bruno/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/bruno/anaconda3/envs/tensorflow/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/bruno/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/home/bruno/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tornado/platform/asyncio.py\", line 112, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/bruno/anaconda3/envs/tensorflow/lib/python3.5/asyncio/base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"/home/bruno/anaconda3/envs/tensorflow/lib/python3.5/asyncio/base_events.py\", line 1425, in _run_once\n    handle._run()\n  File \"/home/bruno/anaconda3/envs/tensorflow/lib/python3.5/asyncio/events.py\", line 127, in _run\n    self._callback(*self._args)\n  File \"/home/bruno/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tornado/ioloop.py\", line 760, in _run_callback\n    ret = callback()\n  File \"/home/bruno/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/bruno/anaconda3/envs/tensorflow/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 536, in <lambda>\n    self.io_loop.add_callback(lambda : self._handle_events(self.socket, 0))\n  File \"/home/bruno/anaconda3/envs/tensorflow/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/home/bruno/anaconda3/envs/tensorflow/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/bruno/anaconda3/envs/tensorflow/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/bruno/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/bruno/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/bruno/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/bruno/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/bruno/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/bruno/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/bruno/anaconda3/envs/tensorflow/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/bruno/anaconda3/envs/tensorflow/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/bruno/anaconda3/envs/tensorflow/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-8-7c15d6e2b819>\", line 1, in <module>\n    saver = tf.train.Saver()\n  File \"/home/bruno/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 1218, in __init__\n    self.build()\n  File \"/home/bruno/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 1227, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/home/bruno/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 1263, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"/home/bruno/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 751, in _build_internal\n    restore_sequentially, reshape)\n  File \"/home/bruno/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 427, in _AddRestoreOps\n    tensors = self.restore_op(filename_tensor, saveable, preferred_shard)\n  File \"/home/bruno/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 267, in restore_op\n    [spec.tensor.dtype])[0])\n  File \"/home/bruno/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 1021, in restore_v2\n    shape_and_slices=shape_and_slices, dtypes=dtypes, name=name)\n  File \"/home/bruno/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/bruno/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/home/bruno/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nNotFoundError (see above for traceback): Key generator/fc1/batch_normalization/gamma not found in checkpoint\n\t [[Node: save/RestoreV2_47 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2_47/tensor_names, save/RestoreV2_47/shape_and_slices)]]\n\t [[Node: save/RestoreV2_45/_95 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_282_save/RestoreV2_45\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    474\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Key generator/fc1/batch_normalization/gamma not found in checkpoint\n\t [[Node: save/RestoreV2_47 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2_47/tensor_names, save/RestoreV2_47/shape_and_slices)]]\n\t [[Node: save/RestoreV2_45/_95 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_282_save/RestoreV2_45\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-7c15d6e2b819>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msaver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSaver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./saved_models/'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'logdir'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./saved_models/'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'logdir'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'no model found'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1664\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_graph_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1665\u001b[0m       sess.run(self.saver_def.restore_op_name,\n\u001b[0;32m-> 1666\u001b[0;31m                {self.saver_def.filename_tensor_name: save_path})\n\u001b[0m\u001b[1;32m   1667\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1668\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_eager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_save\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuild_restore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1334\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Key generator/fc1/batch_normalization/gamma not found in checkpoint\n\t [[Node: save/RestoreV2_47 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2_47/tensor_names, save/RestoreV2_47/shape_and_slices)]]\n\t [[Node: save/RestoreV2_45/_95 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_282_save/RestoreV2_45\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n\nCaused by op 'save/RestoreV2_47', defined at:\n  File \"/home/bruno/anaconda3/envs/tensorflow/lib/python3.5/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/bruno/anaconda3/envs/tensorflow/lib/python3.5/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/bruno/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/__main__.py\", line 3, in <module>\n    app.launch_new_instance()\n  File \"/home/bruno/anaconda3/envs/tensorflow/lib/python3.5/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/bruno/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"/home/bruno/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tornado/platform/asyncio.py\", line 112, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/bruno/anaconda3/envs/tensorflow/lib/python3.5/asyncio/base_events.py\", line 421, in run_forever\n    self._run_once()\n  File \"/home/bruno/anaconda3/envs/tensorflow/lib/python3.5/asyncio/base_events.py\", line 1425, in _run_once\n    handle._run()\n  File \"/home/bruno/anaconda3/envs/tensorflow/lib/python3.5/asyncio/events.py\", line 127, in _run\n    self._callback(*self._args)\n  File \"/home/bruno/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tornado/ioloop.py\", line 760, in _run_callback\n    ret = callback()\n  File \"/home/bruno/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/bruno/anaconda3/envs/tensorflow/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 536, in <lambda>\n    self.io_loop.add_callback(lambda : self._handle_events(self.socket, 0))\n  File \"/home/bruno/anaconda3/envs/tensorflow/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"/home/bruno/anaconda3/envs/tensorflow/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/bruno/anaconda3/envs/tensorflow/lib/python3.5/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/bruno/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/bruno/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/bruno/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/bruno/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/bruno/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/bruno/anaconda3/envs/tensorflow/lib/python3.5/site-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/bruno/anaconda3/envs/tensorflow/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/bruno/anaconda3/envs/tensorflow/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2850, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/bruno/anaconda3/envs/tensorflow/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-8-7c15d6e2b819>\", line 1, in <module>\n    saver = tf.train.Saver()\n  File \"/home/bruno/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 1218, in __init__\n    self.build()\n  File \"/home/bruno/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 1227, in build\n    self._build(self._filename, build_save=True, build_restore=True)\n  File \"/home/bruno/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 1263, in _build\n    build_save=build_save, build_restore=build_restore)\n  File \"/home/bruno/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 751, in _build_internal\n    restore_sequentially, reshape)\n  File \"/home/bruno/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 427, in _AddRestoreOps\n    tensors = self.restore_op(filename_tensor, saveable, preferred_shard)\n  File \"/home/bruno/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/training/saver.py\", line 267, in restore_op\n    [spec.tensor.dtype])[0])\n  File \"/home/bruno/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/ops/gen_io_ops.py\", line 1021, in restore_v2\n    shape_and_slices=shape_and_slices, dtypes=dtypes, name=name)\n  File \"/home/bruno/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/bruno/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/home/bruno/anaconda3/envs/tensorflow/lib/python3.5/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nNotFoundError (see above for traceback): Key generator/fc1/batch_normalization/gamma not found in checkpoint\n\t [[Node: save/RestoreV2_47 = RestoreV2[dtypes=[DT_FLOAT], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](_arg_save/Const_0_0, save/RestoreV2_47/tensor_names, save/RestoreV2_47/shape_and_slices)]]\n\t [[Node: save/RestoreV2_45/_95 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device_incarnation=1, tensor_name=\"edge_282_save/RestoreV2_45\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "if tf.train.latest_checkpoint(os.path.join('./saved_models/',params['logdir'])) is not None:\n",
    "    path = saver.restore(sess, tf.train.latest_checkpoint(os.path.join('./saved_models/',params['logdir'])))\n",
    "else:\n",
    "    print('no model found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-27T10:34:39.859490Z",
     "start_time": "2018-04-27T10:34:24.961484Z"
    },
    "nbpresent": {
     "id": "f6002306-8bea-433f-ac5d-dcc418150de1"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fs = []\n",
    "frames = []\n",
    "np_samples = []\n",
    "n_batches_viz = 1\n",
    "viz_every = 100\n",
    "lsd=[]\n",
    "lsg=[]\n",
    "for i in tqdm(range(20000)):\n",
    "#     f, _= sess.run([[loss], train_op],{is_training_pl:True})\n",
    "    ld,_=sess.run([loss_d,traind],{is_training_pl:True})\n",
    "    lg,_=sess.run([loss_g, traing],{is_training_pl:True})\n",
    "    lsd.append(ld); lsg.append(lg);\n",
    "\n",
    "    if (i) % viz_every == 0:\n",
    "        xx, yy = sess.run([data,samples],{is_training_pl:False})\n",
    "#         print('iter nr : ',gstep)\n",
    "        plt.figure(figsize=(15,5))\n",
    "        plt.subplot(121)\n",
    "        show_digits(xx[:100])\n",
    "        plt.subplot(122)\n",
    "        show_digits(yy[:100])\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(params['logdir']):\n",
    "    os.makedirs(params['logdir'])\n",
    "saver.save(sess, os.path.join('./saved_models/',params['logdir'],params['name_model']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper param perturbation DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_dnn = dict(\n",
    "    epsilon = .1,\n",
    "    gamma = 0.1, #2.\n",
    "    delta = 0.01,\n",
    "    batch = 50,\n",
    "    mc = 200,\n",
    "    lr=1e-3,\n",
    "    beta1 = 0.9,\n",
    "    epoch = 4000,\n",
    "    l2_w = 0.1,\n",
    "    labeled = 10000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# labeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled = params_dnn['labeled']\n",
    "inds = rng.permutation(trainx.shape[0])\n",
    "trainx = trainx[inds]\n",
    "trainy = trainy[inds]\n",
    "txs = []\n",
    "tys = []\n",
    "for j in range(10):\n",
    "    txs.append(trainx[trainy == j][:labeled])\n",
    "    tys.append(trainy[trainy == j][:labeled])\n",
    "txs = np.concatenate(txs, axis=0)\n",
    "tys = np.concatenate(tys, axis=0)\n",
    "trainx = txs\n",
    "trainy = tys\n",
    "\n",
    "nr_batch_train = trainx.shape[0] // params['batch_size']\n",
    "nr_batch_test = testx.shape[0] // params['batch_size']\n",
    "\n",
    "show_digits(trainx[:1000])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_dnn = dict(\n",
    "    epsilon = .1,\n",
    "    gamma = 0.0, #2.\n",
    "    delta = 0.01,\n",
    "    batch = 50,\n",
    "    mc = 200,\n",
    "    lr=1e-3,\n",
    "    beta1 = 0.9,\n",
    "    epoch = 4000,\n",
    "    l2_w = 0.1,\n",
    "    labeled = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((trainx, trainy))\n",
    "train_dataset = train_dataset.shuffle(10000).repeat().batch(params_dnn['batch'])\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((testx, testy))\n",
    "test_dataset = test_dataset.repeat().batch(params_dnn['batch'])\n",
    "\n",
    "iterator = tf.data.Iterator.from_structure(train_dataset.output_types,\n",
    "                                               train_dataset.output_shapes)\n",
    "next_element, next_label = iterator.get_next()\n",
    "next_label = tf.cast(next_label,tf.int64)\n",
    "\n",
    "train_trigger = iterator.make_initializer(train_dataset)\n",
    "test_trigger = iterator.make_initializer(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "z = tf.random_normal(shape=[params_dnn['mc'],params['z_dim']]) # samples = generator(noise,is_training_pl,reuse=False)\n",
    "# perturb = tf.random_normal([params_dnn['mc'],params['z_dim']], mean=0, stddev=1)\n",
    "# perturb_n = tf.nn.l2_normalize(perturb, dim=[1])\n",
    "# z_pert = z + params_dnn['delta']* perturb_n\n",
    "# z_pert = z + tf.random_normal([params_dnn['mc'],params['z_dim']], mean=0, stddev=0.1)\n",
    "\n",
    "# samp_pert = generator(z_pert,is_training_pl,reuse=True)\n",
    "samp = generator(z,is_training_pl,reuse=True)\n",
    "# # samp_adv = samp + params_dnn['epsilon']* tf.nn.l2_normalize(samp_pert-samp,dim=[1])\n",
    "# samp_adv = samp_pert\n",
    "\n",
    "# f_samp_adv = soft(lenet(samp_adv,training_cnn))\n",
    "f_samp = soft(lenet(samp,training_cnn))\n",
    "# tan_consistency = tf.sqrt(1e-8 + tf.pow(f_samp_adv-f_samp,2))\n",
    "# tan_loss = tf.reduce_mean(tan_consistency)\n",
    "\n",
    "# _nabla = tf.gradients(tan_consistency, perturb)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# loss = xloss + params_dnn['gamma'] * tan_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vizualizing perturbation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx,yy = sess.run([samp,f_samp],{is_training_pl:False,training_cnn:False})\n",
    "\n",
    "show_digits(xx[:100])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(yy.flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## defining model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lenet(x,training_pl):\n",
    "    with tf.variable_scope(\"classifier\", reuse=tf.AUTO_REUSE):\n",
    "        x = tf.reshape(x,[-1,28,28,1])\n",
    "        x = tf.layers.conv2d(x,32,5,activation=tf.nn.relu,padding='same')\n",
    "        x = tf.layers.max_pooling2d(x,2,2)\n",
    "        x = tf.layers.conv2d(x,64,5,activation=tf.nn.relu,padding='same')\n",
    "        x = tf.layers.max_pooling2d(x,2,2)\n",
    "        x = tf.layers.flatten(x)\n",
    "        x = tf.layers.dense(x,1024,activation=tf.nn.relu)\n",
    "        x = tf.layers.dropout(x,rate=0.4,training=training_pl)\n",
    "        x = tf.layers.dense(x,10)\n",
    "        return x\n",
    "    \n",
    "soft = lambda x: 1/(1+tf.exp(-x))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = tf.cast(next_label,tf.int64)\n",
    "training_cnn  = tf.placeholder(tf.bool,[])\n",
    "logits = lenet(next_element,training_cnn)\n",
    "xloss = tf.losses.sparse_softmax_cross_entropy(logits=logits,labels=label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.variable_scope(\"classifier\", reuse=tf.AUTO_REUSE):\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate=params_dnn['lr'])\n",
    "    train_op = optimizer.minimize(loss,var_list=tf.trainable_variables(scope='classifier'))\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(logits,1),label)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "#init\n",
    "var = tf.global_variables(scope='classifier')\n",
    "init_op = tf.variables_initializer(var_list=var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cnn training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run([train_trigger,init_op])\n",
    "manifold=[];xentropy=[];vaccu=[];taccu=[];\n",
    "for i in tqdm(range(params_dnn['epoch']+1)):\n",
    "    xl,_,acc,tl = sess.run([xloss,train_op,accuracy,tan_loss],feed_dict={training_cnn:True,is_training_pl:False})\n",
    "    manifold.append(tl); xentropy.append(xl);taccu.append(acc*100)\n",
    "    if i % 100 == 0:\n",
    "        sess.run(test_trigger)\n",
    "        test_acc = 0\n",
    "        for n in range(nr_batch_test):\n",
    "            test_acc  += sess.run(accuracy,feed_dict={training_cnn:False,is_training_pl:False})\n",
    "        test_acc /= nr_batch_test\n",
    "        vaccu.append((test_acc*100,i))\n",
    "        print(\"Step: {}, xloss: {:.5f}, training acc: {:.2f}%, test acc: {:.2f}%\".format(i, xl, acc * 100,test_acc*100))\n",
    "        sess.run(train_trigger)\n",
    "        \n",
    "        if (i != 0) & (i % 500 ==0):\n",
    "            v = np.vstack(vaccu)\n",
    "            plt.figure(figsize=(15,5))\n",
    "            plt.subplot(121)\n",
    "            plt.plot(manifold)\n",
    "            plt.plot(xentropy)\n",
    "            plt.plot(manifold_cnn)\n",
    "            plt.plot(xentropy_cnn)\n",
    "            plt.subplot(122)\n",
    "            plt.plot(v[:,1],v[:,0])\n",
    "            plt.plot(taccu)\n",
    "            plt.plot(v_cnn[:,1],v_cnn[:,0])\n",
    "            plt.plot(taccu_cnn)\n",
    "\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# manifold_cnn = manifold\n",
    "# xentropy_cnn = xentropy\n",
    "# v_cnn = v\n",
    "# taccu_cnn = taccu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "145px",
    "left": "-163.02px",
    "right": "20px",
    "top": "261.409px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
