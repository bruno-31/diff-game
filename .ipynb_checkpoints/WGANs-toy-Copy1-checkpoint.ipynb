{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "% pylab inline\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from tensorflow.contrib.kfac.python.ops.utils import fwd_gradients\n",
    "import seaborn as sns\n",
    "try:\n",
    "    from moviepy.video.io.bindings import mplfig_to_npimage\n",
    "    import moviepy.editor as mpy\n",
    "except:\n",
    "    print(\"Warning: moviepy not found.\")\n",
    "\n",
    "slim = tf.contrib.slim\n",
    "ds = tf.contrib.distributions\n",
    "\n",
    "from universal_divergence import estimate\n",
    "from utils import nn_l2_mean\n",
    "\n",
    "from functools import reduce\n",
    "from operator import mul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from optimizers import OptimisticAdamOptimizer, OptimisticMirrorDescentOptimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Generator and discriminator architectures\n",
    "\n",
    "(same architecture as proposed in google brain paper)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generator(z, output_dim=2, n_hidden=512, n_layer=4, getter=None, reuse=False):\n",
    "    with tf.variable_scope(\"generator\", custom_getter=getter, reuse=reuse):\n",
    "        h = slim.stack(z, slim.fully_connected, [n_hidden] * n_layer, activation_fn=tf.nn.relu)\n",
    "        x = slim.fully_connected(h, output_dim, activation_fn=None)\n",
    "    return x\n",
    "\n",
    "def discriminator(x, n_hidden=512, n_layer=4, getter=None, reuse=False):\n",
    "    with tf.variable_scope(\"discriminator\", custom_getter=getter, reuse=reuse):\n",
    "        h = slim.stack(x, slim.fully_connected, [n_hidden] * n_layer, activation_fn=tf.nn.relu)\n",
    "        log_d = slim.fully_connected(h, 1, activation_fn=None)\n",
    "    return log_d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sample_mog(batch_size, n_mixture=16, std=0.2):\n",
    "    x = np.linspace(-4.5,4.5,4)\n",
    "    xs, ys = np.meshgrid(x, x)\n",
    "    xs, ys = xs.flatten(), ys.flatten()\n",
    "    cat = ds.Categorical(tf.zeros(n_mixture))\n",
    "    comps = [ds.MultivariateNormalDiag([xi, yi], [std, std]) for xi, yi in zip(xs.ravel(), ys.ravel())]\n",
    "    data = ds.Mixture(cat, comps)\n",
    "    return data.sample(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_mnist_and_sample(batch_size):\n",
    "    from tensorflow.examples.tutorials.mnist import input_data\n",
    "    mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "    from sampler import sampler\n",
    "    \n",
    "    im=mnist.train.next_batch(1)[0]\n",
    "    im=im.reshape([28,28])\n",
    "    \n",
    "    x = np.linspace(0, 1, 28)\n",
    "    y = np.linspace(0, 1,28)\n",
    "    xv, yv = np.meshgrid(x, y)\n",
    "    z=im\n",
    "    s=sampler(x,y,z)\n",
    "    vals = s.sample(batch_size)\n",
    "    \n",
    "    return vals,im\n",
    "    \n",
    "def plot_vals_im(vals,im):\n",
    "    xVals = []; yVals = []\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=2)\n",
    "    for item in vals:  # plot point by point\n",
    "            xVals.append(item[0])\n",
    "            yVals.append(item[1])\n",
    "            ax[0].plot(item[0], 1-item[1], marker=\"x\", c=\"red\")\n",
    "            ax[0].set_title('Complex distribution')\n",
    "    \n",
    "    ax[1].imshow(im,cmap='gray')\n",
    "    ax[1].set_title('Original Image')\n",
    "    plt.show()\n",
    "\n",
    "def sample_complex(batch_size):\n",
    "    vals, im = load_mnist_and_sample(batch_size)\n",
    "    plot_vals_im(vals,im)\n",
    "    \n",
    "    return tf.stack(vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = dict(\n",
    "    batch_size=512,\n",
    "    disc_learning_rate=5e-5,\n",
    "    gen_learning_rate=5e-5,\n",
    "    beta1=0.5,\n",
    "    epsilon=1e-8,\n",
    "    max_iter=20000,\n",
    "    frame_every=2000, \n",
    "    viz_every=2000,\n",
    "    z_dim=2,\n",
    "    x_dim=2,\n",
    "    optimizer='consensus', # prop sgd sga\n",
    "    ema = False,\n",
    "    align = True,\n",
    "    data = 'mog',\n",
    "    LAMBDA = .1,\n",
    "    mode = 'wgan-gp',\n",
    "    generate_movie = False,\n",
    "    reg_w = 10,\n",
    "    CRITIC_ITERS = 5 # How many critic iterations per generator iteration\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function for Symplectic gradient adjustment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def jac_vec(ys,xs,vs):\n",
    "    return fwd_gradients(ys,xs,grad_xs=vs, stop_gradients=xs)\n",
    "\n",
    "def jac_tran_vec(ys,xs,vs):\n",
    "    dydxs = tf.gradients(ys,xs,grad_ys=vs, stop_gradients=xs)\n",
    "    return [tf.zeros_like(x) if dydx is None else dydx for (x,dydx) in zip(xs,dydxs)]\n",
    "\n",
    "def get_sym_adj(Ls,xs):\n",
    "    xi= [tf.gradients(l,x)[0]for(l,x)in zip(Ls,xs)]\n",
    "    H_xi = jac_vec(xi,xs,xi)\n",
    "    Ht_xi = jac_tran_vec(xi,xs,xi)\n",
    "    At_xi =[(ht-h)/2 for (h,ht) in zip(H_xi,Ht_xi)]\n",
    "    return At_xi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct model and training ops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "data = sample_complex(params['batch_size']) if params['data']=='complex' else sample_mog(params['batch_size'])\n",
    "noise = ds.Normal(tf.zeros(params['z_dim']), tf.ones(params['z_dim'])).sample(params['batch_size'])\n",
    "\n",
    "# Construct generator and discriminator nets\n",
    "with slim.arg_scope([slim.fully_connected], weights_initializer=tf.orthogonal_initializer(gain=1.4)):\n",
    "    samples = generator(noise, output_dim=params['x_dim'])\n",
    "    real_score = discriminator(data)\n",
    "    fake_score = discriminator(samples, reuse=True)\n",
    "    \n",
    "# Saddle objective    \n",
    "loss = tf.reduce_mean(\n",
    "    tf.nn.sigmoid_cross_entropy_with_logits(logits=real_score, labels=tf.ones_like(real_score)) +\n",
    "    tf.nn.sigmoid_cross_entropy_with_logits(logits=fake_score, labels=tf.zeros_like(fake_score)))\n",
    "\n",
    "loss_gen = -tf.reduce_mean(fake_score)\n",
    "loss_dis = tf.reduce_mean(fake_score) - tf.reduce_mean(real_score)\n",
    "\n",
    "gen_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"generator\")\n",
    "disc_vars = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, \"discriminator\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### WGAN or WGAN-GP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if params['mode'] == 'wgan':\n",
    "    \n",
    "    clip_ops = []\n",
    "    for var in disc_vars:\n",
    "        clip_bounds = [-.01, .01]\n",
    "        clip_ops.append(\n",
    "            tf.assign(\n",
    "                var, \n",
    "                tf.clip_by_value(var, clip_bounds[0], clip_bounds[1])\n",
    "            )\n",
    "        )\n",
    "    clip_disc_weights = tf.group(*clip_ops)\n",
    "    \n",
    "elif params['mode'] == 'wgan-gp':\n",
    "    fake_data = samples\n",
    "    real_data = data\n",
    "\n",
    "    # Gradient penalty\n",
    "    alpha = tf.random_uniform(\n",
    "        shape=[params['batch_size'],1], \n",
    "        minval=0.,\n",
    "        maxval=1.\n",
    "    )\n",
    "    differences = fake_data - real_data\n",
    "    interpolates = real_data + (alpha*differences)\n",
    "    gradients = tf.gradients(discriminator(interpolates,reuse=True), [interpolates])[0]\n",
    "    slopes = tf.sqrt(tf.reduce_sum(tf.square(gradients), reduction_indices=[1]))\n",
    "    gradient_penalty = tf.reduce_mean((slopes-1.)**2)\n",
    "    loss_dis += params['LAMBDA']*gradient_penalty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if params['optimizer'] == 'default':\n",
    "    d_train_opt = tf.train.RMSPropOptimizer(learning_rate=5e-5)\n",
    "    g_train_opt = tf.train.RMSPropOptimizer(learning_rate=5e-5)\n",
    "\n",
    "    d_train_op = d_train_opt.minimize(loss_dis, var_list=disc_vars)\n",
    "    g_train_op = g_train_opt.minimize(loss_gen, var_list=gen_vars)\n",
    "\n",
    "elif params['optimizer'] == 'default_ema':\n",
    "    \n",
    "    d_train_opt = tf.train.RMSPropOptimizer(learning_rate=5e-5)\n",
    "    g_train_opt = tf.train.RMSPropOptimizer(learning_rate=5e-5)\n",
    "\n",
    "    d_train_op = d_train_opt.minimize(loss_dis, var_list=disc_vars)\n",
    "    g_train_op = g_train_opt.minimize(loss_gen, var_list=gen_vars)\n",
    "\n",
    "    ema = tf.train.ExponentialMovingAverage(decay=0.999)\n",
    "    maintain_averages_op = ema.apply(gen_vars)\n",
    "    with tf.control_dependencies([g_train_op]):\n",
    "        g_train_op = tf.group(maintain_averages_op)\n",
    "    samples_ema = generator(noise, output_dim=params['x_dim'], getter=get_getter(ema),reuse=True)\n",
    "\n",
    "elif params['optimizer'] == 'omd':\n",
    "    d_train_opt = OptimisticMirrorDescentOptimizer(learning_rate=5e-5)\n",
    "    g_train_opt = OptimisticMirrorDescentOptimizer(learning_rate=5e-5)\n",
    "    \n",
    "    d_train_op = d_train_opt.minimize(loss_dis, var_list=disc_vars)\n",
    "    g_train_op = g_train_opt.minimize(loss_gen, var_list=gen_vars)\n",
    "    \n",
    "elif params['optimizer'] == 'optimadam':\n",
    "    d_train_opt = OptimisticAdamOptimizer(learning_rate=1e-4, beta1=0.5, beta2=0.9)\n",
    "    g_train_opt = OptimisticAdamOptimizer(learning_rate=1e-4, beta1=0.5, beta2=0.9)\n",
    "    \n",
    "    d_train_op = d_train_opt.minimize(loss_dis, var_list=disc_vars)\n",
    "    g_train_op = g_train_opt.minimize(loss_gen, var_list=gen_vars)\n",
    "\n",
    "elif params['optimizer'] == 'sga': \n",
    "\n",
    "    d_opt = tf.train.RMSPropOptimizer(learning_rate=params['disc_learning_rate'])\n",
    "    g_opt = tf.train.RMSPropOptimizer(learning_rate=params['gen_learning_rate'])\n",
    "\n",
    "    dvs = d_opt.compute_gradients(loss_dis, var_list=disc_vars)\n",
    "    gvs = g_opt.compute_gradients(loss_gen, var_list=gen_vars)\n",
    "\n",
    "    adj = get_sym_adj([loss_dis]*len(disc_vars) + [loss_gen]*len(gen_vars),disc_vars+gen_vars)\n",
    "    d_adj= adj[:len(disc_vars)]\n",
    "    g_adj = adj[-len(gen_vars)::]\n",
    "\n",
    "    dvs_sga = [(grad + adj , var) for (grad,var),adj in zip(dvs,d_adj)]\n",
    "    gvs_sga = [(grad + adj , var) for (grad,var),adj in zip(gvs,g_adj)]\n",
    "\n",
    "    d_train_op = d_opt.apply_gradients(dvs_sga)\n",
    "    g_train_op = g_opt.apply_gradients(gvs_sga)\n",
    "    \n",
    "elif params['optimizer'] == 'consensus': \n",
    "    \n",
    "    d_opt = tf.train.RMSPropOptimizer(learning_rate=params['disc_learning_rate'], use_locking=True)\n",
    "    g_opt = tf.train.RMSPropOptimizer(learning_rate=params['gen_learning_rate'], use_locking=True)\n",
    "\n",
    "    dvs = d_opt.compute_gradients(loss_dis, var_list=disc_vars)\n",
    "    gvs = g_opt.compute_gradients(loss_gen, var_list=gen_vars)\n",
    "\n",
    "    grads_d = [grad for (grad,var) in dvs]\n",
    "    grads_g = [grad for (grad,var) in gvs]\n",
    "    grads = grads_d + grads_g\n",
    "\n",
    "    # Regularizer\n",
    "    reg = 0.5 * sum(tf.reduce_sum(tf.square(g)) for g in grads)\n",
    "    # Jacobian times gradiant\n",
    "    variables = disc_vars + gen_vars\n",
    "    Jgrads = tf.gradients(reg, variables)\n",
    "    \n",
    "    d_adj = Jgrads[:len(disc_vars)]\n",
    "    g_adj = Jgrads[-len(gen_vars)::]\n",
    "    \n",
    "    dvs_sga = [(grad + params['reg_w'] * adj , var) for (grad,var),adj in zip(dvs,d_adj)]\n",
    "    gvs_sga = [(grad + params['reg_w'] * adj , var) for (grad,var),adj in zip(gvs,g_adj)]\n",
    "    \n",
    "    with tf.control_dependencies([g for (g, v) in dvs_sga]):\n",
    "        d_train_op = d_opt.apply_gradients(dvs_sga)\n",
    "    with tf.control_dependencies([g for (g, v) in dvs_sga]):\n",
    "        g_train_op = g_opt.apply_gradients(gvs_sga)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xmax = 3\n",
    "fs = []\n",
    "raw_frames = []\n",
    "np_samples = []\n",
    "n_batches_viz = 10\n",
    "viz_every = params['viz_every']\n",
    "frame_every = params['frame_every']\n",
    "\n",
    "nn_every = 200\n",
    "y_ref = sess.run(data)\n",
    "nn_dist = []\n",
    "nn_kl =[]\n",
    "\n",
    "for i in tqdm(range(params['max_iter']+1)):\n",
    "    f, _ = sess.run([[loss], g_train_op])\n",
    "    for j in range(params['CRITIC_ITERS']):\n",
    "        _ = sess.run(d_train_op)\n",
    "        if params['mode'] == 'wgan':\n",
    "            _ = sess.run(clip_disc_weights)\n",
    "    fs.append(f)\n",
    "    if (i) % frame_every == 0:\n",
    "        if params['optimizer'] == 'default_ema':\n",
    "            np_samples.append(np.vstack([sess.run(samples_ema) for _ in range(n_batches_viz)]))\n",
    "            xx, yy = sess.run([samples_ema, data])\n",
    "        else:\n",
    "            np_samples.append(np.vstack([sess.run(samples) for _ in range(n_batches_viz)]))\n",
    "            xx, yy = sess.run([samples, data])\n",
    "\n",
    "        fig = figure(figsize=(5,5))\n",
    "        scatter(xx[:, 0], xx[:, 1], edgecolor='none',s=10)\n",
    "        scatter(yy[:, 0], yy[:, 1], c='g', edgecolor='none',s=10)\n",
    "        if params[\"data\"]==\"complex\":\n",
    "            plt.xlim([-0.2, 1.2])\n",
    "            plt.ylim([-0.2, 1.2])\n",
    "        else:\n",
    "            plt.xlim([-5.5, 5.5])\n",
    "            plt.ylim([-5.5, 5.5])\n",
    "        axis('off')\n",
    "        if params['generate_movie']:\n",
    "            raw_frames.append(mplfig_to_npimage(fig))\n",
    "        if (i) % viz_every == 0:\n",
    "            show()\n",
    "            \n",
    "    if (i) % nn_every == 0:\n",
    "        if params['optimizer'] == 'default_ema':\n",
    "            x = np.vstack([sess.run(samples_ema) for _ in range(n_batches_viz)])\n",
    "        else:\n",
    "            x = np.vstack([sess.run(samples) for _ in range(n_batches_viz)])\n",
    "        l2nn = nn_l2_mean(x,y_ref)\n",
    "        kl =estimate(x, y_ref,k=1)\n",
    "        nn_dist.append(l2nn)\n",
    "        nn_kl.append(kl)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np_samples_ = np_samples[::1]\n",
    "vizu_frames = []\n",
    "cols = len(np_samples_)\n",
    "figure(figsize=(2*cols, 2))\n",
    "for i, samps in enumerate(np_samples_):\n",
    "    if i == 0:\n",
    "        ax = subplot(1,cols,1)\n",
    "    else:\n",
    "        subplot(1,cols,i+1, sharex=ax, sharey=ax)\n",
    "    ax2 = sns.kdeplot(samps[:, 0], samps[:, 1], shade=True, cmap='coolwarm', bw=.40, n_levels=20, clip=[[-6,6]]*2)\n",
    "    xticks([]); yticks([])\n",
    "    title('step %d'%(i*viz_every))\n",
    "gcf().tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.semilogy(nn_dist)\n",
    "plt.semilogy(nn_kl)\n",
    "plt.legend(['kl','l2 nearest neigbhors'])\n",
    "xlabel('iterations')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('plot_{}_{}_kl'.format(params['mode'],params['optimizer']),nn_kl)\n",
    "np.save('plot_{}_{}_nn'.format(params['mode'],params['optimizer']),nn_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Video maker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if params['generate_movie']:\n",
    "    np_samples_ = np_samples[::1]\n",
    "    vizu_frames = []\n",
    "    cols = len(np_samples_)\n",
    "    bg_color  = sns.color_palette('Greens', n_colors=256)[0]\n",
    "    fig, ax = plt.subplots()\n",
    "    for i, samps in enumerate(np_samples_):\n",
    "        ax.clear()\n",
    "        ax2 = sns.kdeplot(samps[:, 0], samps[:, 1], shade=True, cmap='coolwarm', bw=.40, n_levels=20, clip=[[-6,6]]*2)\n",
    "\n",
    "        xticks([]); yticks([])\n",
    "        title('step %d'%(i*frame_every))\n",
    "        if generate_movie:\n",
    "            vizu_frames.append(mplfig_to_npimage(fig))\n",
    "    \n",
    "    # Generate movie\n",
    "    \n",
    "    raw_clip = mpy.ImageSequenceClip(raw_frames[::], fps=10)\n",
    "    raw_clip.write_videofile(\"raw_optimizer_{}_{}_{}.webm\".format(params['optimizer'], params['mode'], params['data']), audio=False)\n",
    "    vizu_clip = mpy.ImageSequenceClip(vizu_frames[::], fps=10)\n",
    "    vizu_clip.write_videofile(\"vizu_optimizer_{}_{}_{}.webm\".format(params['optimizer'], params['mode'], params['data']), audio=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TF 1.6",
   "language": "python",
   "name": "tensorflow-1.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
